# 프로젝트 회고
- 사람이 인식하는 데이터와 AI가 인식하는 데이터는 다르다
    - 데이터 품질을 어느 기준에 맞춰야 할까? 그래도 해석 가능성을 위해 사람 기준? 어쨌든 우수한 성능이 목표이니 결과 중심으로 봐야 하나? (사람이 납득하기 힘든 노이즈 데이터라 하더라도?)
- 중복 데이터 또는 유사한 데이터를 제거하니 성능이 오른다
    - 동일한 데이터를 전략적으로 군데군데 잘 입력하면, epoch을 늘리는 것과 동일한 효과 있을 수 있나? (중복 데이터이지만 성능이 오를 수 있는 경우는 없나?)
- 텍스트 노이즈 정도를 다른 방식으로 탐색해볼 수도 있었겠다.
    - 시도해본 방법
        1. 형태소 분석 기반 rule base 노이즈 함수 정의
        2. bert 모델에서 `[CLS]` 토큰의 임베딩 벡터로 perplexity 계산 (노이즈 score 비직관적이라 적용 못함)
    - 다른 가능한 방법들
        - LLM fine-tuning시켜 점수 뱉도록 학습
            - LLM은 숫자에 약하니, '어느 정도의 노이즈 있는지' 정량적으로 판단 잘 못할 수 있음
            - 따라서 '노이즈 여부'를 이진으로 판별하도록 하는 것도 좋았을 것 (결과 발표 팀에서 채택한 접근법이었고, 성능 좋아보였음)
- 데이터 버전 관리 어떻게 할까?
    - v0.0.0 같은 형식으로 처리하고, 구체적인 규칙 정하면 될까?
    - DVC를 사용한다고들 하는데, 어떻게 쓰는걸까?
- 성능 좋은 최신 모델 어떻게 찾을 수 있을까?
    - 여러 리더보드를 자주 봐야겠다
- 클러스터링을 더 살펴보면 좋았을 걸
    - 시각화: 클러스터링 잘 됨을 보이기 위해 t-SNE 등 적용 가능할 것.
        - 다만 n차원의 벡터를 2~3차원에 시각화하는 결과, 얼마나 신뢰할 수 있을까?
    - K-means, DBSCAN만 생각했는데, GMM으로도 클러스터링이 가능함을 배움. 장단점, 어떤 상황에 어떤 클러스터링 방법을 사용하는게 좋을지 더 찾아보면 좋을 것 같다.
- 일단 돌아가는데 만족했던 경향이 있었다. 차분히 생각하면서 명확한 근거 가지고 이해하자. 하나 할 때 제대로 하기.
    - LLaMA 및 LIMA 논문 읽어보고 싶다.
- motivation, 가정, 가설, 실험, 결과 흐름 잘 관리해서 논리적인 실험 진행하기
- data-centric이란 뭘까?
    - 데이터 퀄리티를 높이기 위해 별도의 모델을 만드는 것도 data-centric일 것. 결국은 최종 모델 성능을 끌어올리기 위해 다양한 방법을 시도해보는게 중요하다
    - data-centric이라고 모델링을 안한다는건 아님에 유의
    - 사람이 직접 검수하는게 사실 최적의 방법일 수도 있다. 너무 fancy한 방법론만 찾아볼게 아님.